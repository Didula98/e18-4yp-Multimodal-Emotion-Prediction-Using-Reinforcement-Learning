{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiyumaliSandunika/e18-4yp-Multimodal-Emotion-Prediction-Using-Reinforcement-Learning/blob/main/initial_model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LS8w6tbku0vg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngUoASVOn2AK",
        "outputId": "3a13976c-e107-465b-d928-72cd61890650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNSYY-747pu7"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/FYP_Text/tweet_emotions.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npylGeSiES-8",
        "outputId": "31ddeebe-1974-4128-b2e3-7d995d40da5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment\n",
              "neutral       8638\n",
              "worry         8459\n",
              "happiness     5209\n",
              "sadness       5165\n",
              "love          3842\n",
              "surprise      2187\n",
              "fun           1776\n",
              "relief        1526\n",
              "hate          1323\n",
              "empty          827\n",
              "enthusiasm     759\n",
              "boredom        179\n",
              "anger          110\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df['sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNmU6ZvLFw1m",
        "outputId": "a063fd57-c800-49d1-8040-f76e08b392d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment\n",
            "sadness      13624\n",
            "happiness    10827\n",
            "neutral       8638\n",
            "anger         1433\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df_org = df.sample(frac=1.0, random_state=42)\n",
        "df_org = df_org.drop('tweet_id',axis =1 )\n",
        "# rename 'hate'as 'anger' in sentiments\n",
        "df_org['sentiment'] = df_org['sentiment'].replace('hate','anger')\n",
        "# rename love,fun as joy\n",
        "df_org['sentiment'] = df_org['sentiment'].replace(['love','fun'],'happiness')\n",
        "# rename worry,boredom as sadness\n",
        "df_org['sentiment'] = df_org['sentiment'].replace('worry','sadness')\n",
        "df_org = df_org[df_org['sentiment'].apply(lambda x: x not in ['worry','love','fun','surprise','relief','hate','empty','enthusiasm','boredom'])]\n",
        "print(df_org['sentiment'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0oPaJAjcYZJ",
        "outputId": "14eec3dc-462f-4b71-8373-74212d6a5f32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment\n",
            "anger        1433\n",
            "happiness    1433\n",
            "neutral      1433\n",
            "sadness      1433\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "min_count = df_org['sentiment'].value_counts().min()\n",
        "df_org = df_org.groupby('sentiment').apply(lambda x: x.sample(min_count)).reset_index(drop=True)\n",
        "print(df_org['sentiment'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_zmFHJzeVLm"
      },
      "outputs": [],
      "source": [
        "df = df_org"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txLOzMP37w25"
      },
      "outputs": [],
      "source": [
        "# Extract sentences and labels\n",
        "texts = df[\"content\"].tolist()\n",
        "labels = df[\"sentiment\"].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z67MZBeK76Nt"
      },
      "outputs": [],
      "source": [
        "# Convert emotion labels to numerical values\n",
        "label_map = {\"happiness\": 0, \"sadness\": 1, \"anger\": 2, \"neutral\": 3}\n",
        "labels = [label_map[label] for label in labels]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNbKGdUq8C1F"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split data into train and validation sets\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2)\n",
        "# split dataset into train validation and test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAXwxGiL8Fsq",
        "outputId": "1776f0f1-31f7-41dc-e936-119d9a83d1ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained DistilBERT model and tokenizer\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=4)\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idkNnX6O8MXo"
      },
      "outputs": [],
      "source": [
        "# Tokenize data\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucOv6Ij0-aLt"
      },
      "outputs": [],
      "source": [
        "# Create PyTorch datasets\n",
        "class EmotionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcTBfREM8OzA"
      },
      "outputs": [],
      "source": [
        "train_dataset = EmotionDataset(train_encodings, train_labels)\n",
        "val_dataset = EmotionDataset(val_encodings, val_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBJLmciwBhP3"
      },
      "outputs": [],
      "source": [
        "# from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
        "\n",
        "# # Define hyperparameter search space\n",
        "# param_grid = {\n",
        "#     'learning_rate': [1e-5, 2e-5, 3e-5],\n",
        "#     'batch_size': [16, 32, 64],\n",
        "#     'num_train_epochs': [3, 4, 5],\n",
        "#     'weight_decay': [0.01, 0.001, 0.0001],\n",
        "#     'dropout_rate': [0.1, 0.2, 0.3]\n",
        "# }\n",
        "\n",
        "# # Define model and tokenizer\n",
        "# model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=4)\n",
        "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "git install accelerate\n",
        "# refresh the runtime after execution"
      ],
      "metadata": {
        "id": "f_HEF5L8q9l6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Z5BXrDm8U6X"
      },
      "outputs": [],
      "source": [
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=30,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define a function to compute accuracy\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": accuracy}"
      ],
      "metadata": {
        "id": "34VvsKm2P_t5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b1DT8ub9y6U",
        "outputId": "0ed43067-a71d-4a89-f00e-a02b04088587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Create Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qW4NDFl3BCr5"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import RandomizedSearchCV\n",
        "# from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
        "\n",
        "# # Define hyperparameter search space\n",
        "# param_grid = {\n",
        "#     'learning_rate': [1e-5, 2e-5, 3e-5],\n",
        "#     'batch_size': [16, 32, 64],\n",
        "#     'num_train_epochs': [3, 4, 5],\n",
        "#     'weight_decay': [0.01, 0.001, 0.0001],\n",
        "#     'dropout_rate': [0.1, 0.2, 0.3]\n",
        "# }\n",
        "\n",
        "# # Define model and tokenizer\n",
        "# model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=4)\n",
        "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# # Define Trainer and TrainingArguments (not shown here)\n",
        "\n",
        "# # Define RandomizedSearchCV\n",
        "# random_search = RandomizedSearchCV(estimator=Trainer(model=model, args=training_args),\n",
        "#                                    param_distributions=param_grid,\n",
        "#                                    n_iter=10,\n",
        "#                                    scoring='accuracy',\n",
        "#                                    cv=3,\n",
        "#                                    verbose=2,\n",
        "#                                    random_state=42,\n",
        "#                                    n_jobs=-1)\n",
        "\n",
        "# # Perform random search\n",
        "# random_search.fit(train_dataset)\n",
        "\n",
        "# # Get best hyperparameters\n",
        "# best_hyperparameters = random_search.best_params_\n",
        "\n",
        "# print(\"Best Hyperparameters:\", best_hyperparameters)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "K_i9qVu491XU",
        "outputId": "4cdd67e4-6897-4028-97e6-9c4b5f42c117"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8610' max='8610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8610/8610 21:14, Epoch 30/30]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.132400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.716500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.334300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.152200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.063400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.036200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.018700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.024600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.018700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.012400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.012600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.002700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.004700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Train the model\n",
        "h = trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "x4tc1x5FQBg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = trainer.evaluate()\n",
        "\n",
        "# Print accuracy\n",
        "print(\"Accuracy:\", evaluation_results['eval_accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "cbr5ooRNOoGP",
        "outputId": "42de9263-6276-4b47-c652-7b833899c724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='36' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [18/18 00:09]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5370531822144725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJH5Mhb0_kCC"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "trainer.save_model(\"/content/drive/MyDrive/FYP_Text/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6S3JU4q3U6p"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Save the trained model\n",
        "model_path = \"/content/drive/MyDrive/FYP_Text/ERM_30.pkl\"\n",
        "with open(model_path, 'wb') as f:\n",
        "    pickle.dump(model, f)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}