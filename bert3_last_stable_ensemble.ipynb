{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiyumaliSandunika/e18-4yp-Multimodal-Emotion-Prediction-Using-Reinforcement-Learning/blob/main/bert3_last_stable_ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LS8w6tbku0vg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNSYY-747pu7"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(\"e_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npylGeSiES-8",
        "outputId": "5abca423-70ac-4c0b-ec90-f72557963772"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment\n",
              "angry      150\n",
              "joy        150\n",
              "neutral    150\n",
              "sad        150\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "df['sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNmU6ZvLFw1m",
        "outputId": "66e1fee8-2fe8-438e-a412-7d4b9e32956c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment\n",
            "sad        150\n",
            "joy        150\n",
            "neutral    150\n",
            "angry      150\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df_org = df.sample(frac=1.0, random_state=42)\n",
        "df_org = df_org.drop('tweet_id',axis =1 )\n",
        "# rename 'hate'as 'anger' in sentiments\n",
        "df_org['sentiment'] = df_org['sentiment'].replace('hate','anger')\n",
        "# rename love,fun as joy\n",
        "df_org['sentiment'] = df_org['sentiment'].replace(['love','fun'],'happiness')\n",
        "# rename worry,boredom as sadness\n",
        "df_org['sentiment'] = df_org['sentiment'].replace('worry','sadness')\n",
        "df_org = df_org[df_org['sentiment'].apply(lambda x: x not in ['worry','love','fun','surprise','relief','hate','empty','enthusiasm','boredom'])]\n",
        "print(df_org['sentiment'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0oPaJAjcYZJ",
        "outputId": "59045ccc-8413-4381-810b-b6701e6d52c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment\n",
            "angry      150\n",
            "joy        150\n",
            "neutral    150\n",
            "sad        150\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "min_count = df_org['sentiment'].value_counts().min()\n",
        "df_org = df_org.groupby('sentiment').apply(lambda x: x.sample(min_count)).reset_index(drop=True)\n",
        "print(df_org['sentiment'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_zmFHJzeVLm"
      },
      "outputs": [],
      "source": [
        "df = df_org"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txLOzMP37w25"
      },
      "outputs": [],
      "source": [
        "# Extract sentences and labels\n",
        "texts = df[\"content\"].tolist()\n",
        "labels = df[\"sentiment\"].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z67MZBeK76Nt"
      },
      "outputs": [],
      "source": [
        "# Convert emotion labels to numerical values\n",
        "label_map = {\"happiness\": 0, \"sadness\": 1, \"anger\": 2, \"neutral\": 3}\n",
        "labels = [label_map[label] for label in labels]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNbKGdUq8C1F"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split data into train and validation sets\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2)\n",
        "# split dataset into train validation and test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "pAXwxGiL8Fsq",
        "outputId": "dcb1dc22-f9a3-4087-e281-ad49c5a600db"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'DistilBertForSequenceClassification' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-dd3989aa2041>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load pre-trained DistilBERT model and tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDistilBertForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'distilbert-base-uncased'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDistilBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'distilbert-base-uncased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DistilBertForSequenceClassification' is not defined"
          ]
        }
      ],
      "source": [
        "# Load pre-trained DistilBERT model and tokenizer\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=4)\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idkNnX6O8MXo"
      },
      "outputs": [],
      "source": [
        "# Tokenize data\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucOv6Ij0-aLt"
      },
      "outputs": [],
      "source": [
        "# Create PyTorch datasets\n",
        "class EmotionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcTBfREM8OzA"
      },
      "outputs": [],
      "source": [
        "train_dataset = EmotionDataset(train_encodings, train_labels)\n",
        "val_dataset = EmotionDataset(val_encodings, val_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBJLmciwBhP3"
      },
      "outputs": [],
      "source": [
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
        "\n",
        "# Define hyperparameter search space\n",
        "param_grid = {\n",
        "    'learning_rate': [1e-5, 2e-5, 3e-5],\n",
        "    'batch_size': [16, 32, 64],\n",
        "    'num_train_epochs': [3, 4, 5],\n",
        "    'weight_decay': [0.01, 0.001, 0.0001],\n",
        "    'dropout_rate': [0.1, 0.2, 0.3]\n",
        "}\n",
        "\n",
        "# # Define model and tokenizer\n",
        "# model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=4)\n",
        "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d_ovmwoL9L_",
        "outputId": "39c74778-61d1-44fc-e3f0-5f6ee20b3a4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/290.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/290.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.28.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Z5BXrDm8U6X"
      },
      "outputs": [],
      "source": [
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define a function to compute accuracy\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": accuracy}"
      ],
      "metadata": {
        "id": "34VvsKm2P_t5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b1DT8ub9y6U",
        "outputId": "9754ea48-b469-44ae-b239-77fac81f0ff4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Create Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qW4NDFl3BCr5"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import RandomizedSearchCV\n",
        "# from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
        "\n",
        "# # Define hyperparameter search space\n",
        "# param_grid = {\n",
        "#     'learning_rate': [1e-5, 2e-5, 3e-5],\n",
        "#     'batch_size': [16, 32, 64],\n",
        "#     'num_train_epochs': [3, 4, 5],\n",
        "#     'weight_decay': [0.01, 0.001, 0.0001],\n",
        "#     'dropout_rate': [0.1, 0.2, 0.3]\n",
        "# }\n",
        "\n",
        "# # Define model and tokenizer\n",
        "# model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=4)\n",
        "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# # Define Trainer and TrainingArguments (not shown here)\n",
        "\n",
        "# # Define RandomizedSearchCV\n",
        "# random_search = RandomizedSearchCV(estimator=Trainer(model=model, args=training_args),\n",
        "#                                    param_distributions=param_grid,\n",
        "#                                    n_iter=10,\n",
        "#                                    scoring='accuracy',\n",
        "#                                    cv=3,\n",
        "#                                    verbose=2,\n",
        "#                                    random_state=42,\n",
        "#                                    n_jobs=-1)\n",
        "\n",
        "# # Perform random search\n",
        "# random_search.fit(train_dataset)\n",
        "\n",
        "# # Get best hyperparameters\n",
        "# best_hyperparameters = random_search.best_params_\n",
        "\n",
        "# print(\"Best Hyperparameters:\", best_hyperparameters)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "K_i9qVu491XU",
        "outputId": "0df359d4-6a73-435f-8cf6-2806a7ec9724"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='90' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [90/90 00:05, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Train the model\n",
        "h = trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "x4tc1x5FQBg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = trainer.evaluate()\n",
        "\n",
        "# Print accuracy\n",
        "print(\"Accuracy:\", evaluation_results['eval_accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "cbr5ooRNOoGP",
        "outputId": "c9650081-0773-49e2-9f5c-9a8b754b59be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJH5Mhb0_kCC"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "trainer.save_model(\"emotion_classification_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6S3JU4q3U6p"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Save the trained model\n",
        "model_path = \"emotion_text_classification_model.pkl\"\n",
        "with open(model_path, 'wb') as f:\n",
        "    pickle.dump(model, f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Model Loading**"
      ],
      "metadata": {
        "id": "eo9D1oTAec2b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZe1gEDC_2LT"
      },
      "outputs": [],
      "source": [
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
        "import torch\n",
        "\n",
        "# Load the saved model\n",
        "model_path = \"emotion_classification_model\"\n",
        "loaded_model = DistilBertForSequenceClassification.from_pretrained(model_path)\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path2 = \"emotion_classification_model_lite\"\n",
        "loaded_model2 = DistilBertForSequenceClassification.from_pretrained(model_path)\n",
        "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n"
      ],
      "metadata": {
        "id": "8KVWXF45exdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_emotion_with_probabilities(sentence, model, tokenizer):\n",
        "    # Tokenize the input sentence\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
        "\n",
        "    # Perform inference\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "\n",
        "    # Apply softmax to get probabilities\n",
        "    probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
        "\n",
        "    # Convert probabilities tensor to list\n",
        "    probabilities_list = probabilities.squeeze().tolist()\n",
        "\n",
        "    # Map predicted label to emotion\n",
        "    emotion_labels = [\"happiness\", \"sadness\", \"anger\", \"neutral\"]\n",
        "    predicted_emotion = emotion_labels[torch.argmax(logits, dim=1).item()]\n",
        "\n",
        "    return probabilities_list, predicted_emotion\n"
      ],
      "metadata": {
        "id": "eKPDJ9OMiDsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ensemble_predictions(sentence, model_weights=None, class_weights=None):\n",
        "    # Get predictions from the first model\n",
        "    probabilities1, _ = predict_emotion_with_probabilities(sentence, loaded_model, tokenizer)\n",
        "\n",
        "    # Get predictions from the second model\n",
        "    probabilities2, _ = predict_emotion_with_probabilities(sentence, loaded_model2, tokenizer)\n",
        "\n",
        "    # Apply model-wise weights if provided\n",
        "    if model_weights:\n",
        "        probabilities1 = [p1 * w for p1, w in zip(probabilities1, model_weights[0])]\n",
        "        probabilities2 = [p2 * w for p2, w in zip(probabilities2, model_weights[1])]\n",
        "\n",
        "    # Apply class-wise weights if provided\n",
        "    if class_weights:\n",
        "        probabilities1 = [p1 * w for p1, w in zip(probabilities1, class_weights)]\n",
        "        probabilities2 = [p2 * w for p2, w in zip(probabilities2, class_weights)]\n",
        "\n",
        "    # Calculate ensemble probabilities by averaging\n",
        "    ensemble_probabilities = [(p1 + p2) / 2 for p1, p2 in zip(probabilities1, probabilities2)]\n",
        "\n",
        "    # Map ensemble probabilities to emotion labels\n",
        "    emotion_labels = [\"happiness\", \"sadness\", \"anger\", \"neutral\"]\n",
        "    predicted_emotion = emotion_labels[np.argmax(ensemble_probabilities)]\n",
        "\n",
        "    return probabilities1, probabilities2, ensemble_probabilities, predicted_emotion\n",
        "\n",
        "# Example usage with model and class weights\n",
        "sentence = \"This is a test sentence.\"\n",
        "model_weights = [[1.0, 1.0, 1.0, 1.0], [0.8, 0.8, 0.9, 1.2]]  # Example weights for each model\n",
        "class_weights = [1.0, 1.0, 0.8, 1.2]  # Example weights for each class\n",
        "probabilities1, probabilities2, ensemble_probabilities, predicted_emotion = ensemble_predictions(sentence, model_weights, class_weights)\n",
        "print(\"Probabilities (Model 1):\", probabilities1)\n",
        "print(\"Probabilities (Model 2):\", probabilities2)\n",
        "print(\"Ensemble Probabilities:\", ensemble_probabilities)\n",
        "print(\"Ensemble Predicted Emotion:\", predicted_emotion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4ey-i76Rrn6",
        "outputId": "f7552897-0c74-47ef-8813-6e17690ea8d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probabilities (Model 1): [0.0003059331502299756, 0.0008683084743097425, 0.0019081057980656624, 1.1957287073135376]\n",
            "Probabilities (Model 2): [0.0002447465201839805, 0.000694646779447794, 0.0017172952182590963, 1.434874448776245]\n",
            "Ensemble Probabilities: [0.000275339835206978, 0.0007814776268787682, 0.0018127005081623794, 1.3153015780448913]\n",
            "Ensemble Predicted Emotion: neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qf_zNcMv_4Rm",
        "outputId": "2414f0d6-2ed6-428d-e214-a60a93935fe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: 'I love going to the park, it always makes me happy.'\n",
            "Predicted Emotion: [0.5162611603736877, 0.18221308290958405, 0.15279607474803925, 0.14872965216636658]\n",
            "\n",
            "Predicted Emotion: joy\n",
            "\n",
            "Sentence: 'The loss of my pet dog left me feeling devastated.'\n",
            "Predicted Emotion: [0.2505452036857605, 0.37606674432754517, 0.2137974351644516, 0.15959052741527557]\n",
            "\n",
            "Predicted Emotion: sad\n",
            "\n",
            "Sentence: 'I'm afraid of the dark, it gives me chills.'\n",
            "Predicted Emotion: [0.2281908094882965, 0.3160349130630493, 0.25184106826782227, 0.20393317937850952]\n",
            "\n",
            "Predicted Emotion: sad\n",
            "\n",
            "Sentence: 'The weather today is quite pleasant.'\n",
            "Predicted Emotion: [0.40060093998908997, 0.1721194088459015, 0.1856856793165207, 0.24159397184848785]\n",
            "\n",
            "Predicted Emotion: joy\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Example sentences for prediction\n",
        "sentences = [\n",
        "    \"I love going to the park, it always makes me happy.\",\n",
        "    \"The loss of my pet dog left me feeling devastated.\",\n",
        "    \"I'm afraid of the dark, it gives me chills.\",\n",
        "    \"The weather today is quite pleasant.\"\n",
        "]\n",
        "\n",
        "# Perform prediction for each sentence\n",
        "for sentence in sentences:\n",
        "    probabilities_list, predicted_emotion = predict_emotion(sentence)\n",
        "    print(f\"Sentence: '{sentence}'\")\n",
        "    print(f\"Predicted Emotion: {probabilities_list}\\n\")\n",
        "    print(f\"Predicted Emotion: {predicted_emotion}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKPsIZh-mvOK",
        "outputId": "f5035739-80ac-4fce-8d23-0f9a15d7ce26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: 'I am a broken-hearted'\n",
            "Predicted Emotion: ([0.00020950073667336255, 0.9991468191146851, 0.00019554900063667446, 0.00044807567610405385], 'sadness')\n",
            "\n",
            "Sentence: 'I am emotionaly damaged right now'\n",
            "Predicted Emotion: ([0.00024238182231783867, 0.9989521503448486, 0.000303982145851478, 0.0005014440976083279], 'sadness')\n",
            "\n",
            "Sentence: 'Do what makes feel you better'\n",
            "Predicted Emotion: ([0.0008129614870995283, 0.0006066274363547564, 0.00010575642954790965, 0.998474657535553], 'neutral')\n",
            "\n",
            "Sentence: 'I feel nervous'\n",
            "Predicted Emotion: ([0.0005710084806196392, 0.9955019354820251, 0.0003445712791290134, 0.003582351142540574], 'sadness')\n",
            "\n",
            "Sentence: 'I am a student'\n",
            "Predicted Emotion: ([4.979088043910451e-05, 0.00010799858864629641, 9.025849431054667e-05, 0.9997519850730896], 'neutral')\n",
            "\n",
            "Sentence: 'You're stupid and it makes me anger'\n",
            "Predicted Emotion: ([0.00018839072436094284, 0.0004287665069568902, 0.9992074370384216, 0.0001754151890054345], 'anger')\n",
            "\n",
            "Sentence: 'Go to hell'\n",
            "Predicted Emotion: ([0.00040037883445620537, 0.0004342803731560707, 0.9989655017852783, 0.00019977182091679424], 'anger')\n",
            "\n",
            "Sentence: 'You are the worst,I do not want to see you'\n",
            "Predicted Emotion: ([0.0004904474481008947, 0.0031494456343352795, 0.996150016784668, 0.0002100285200867802], 'anger')\n",
            "\n",
            "Sentence: 'I am angry right now'\n",
            "Predicted Emotion: ([0.00023630667419638485, 0.0003840806311927736, 0.9992228746414185, 0.00015672019799239933], 'anger')\n",
            "\n",
            "Sentence: 'You are my sunshine'\n",
            "Predicted Emotion: ([0.9993209838867188, 0.00010285285679856315, 7.621452095918357e-05, 0.0004999376251362264], 'happiness')\n",
            "\n",
            "Sentence: 'Such a wonderful performance'\n",
            "Predicted Emotion: ([0.9992812275886536, 0.00014037168875802308, 0.00016666164447087795, 0.0004117736534681171], 'happiness')\n",
            "\n",
            "Sentence: 'I am lonely'\n",
            "Predicted Emotion: ([0.00025546664255671203, 0.9991061091423035, 0.0001425319496775046, 0.0004958720528520644], 'sadness')\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Example sentences for prediction\n",
        "sentences = [\n",
        "    \"I am a broken-hearted\",\n",
        "    \"I am emotionaly damaged right now\",\n",
        "    \"Do what makes feel you better\",\n",
        "    \"I feel nervous\",\n",
        "    \"I am a student\",\n",
        "    \"You're stupid and it makes me anger\",\n",
        "    \"Go to hell\",\n",
        "    \"You are the worst,I do not want to see you\",\n",
        "    \"I am angry right now\",\n",
        "    \"You are my sunshine\",\n",
        "    \"Such a wonderful performance\",\n",
        "    \"I am lonely\"\n",
        "]\n",
        "\n",
        "# Perform prediction for each sentence\n",
        "for sentence in sentences:\n",
        "    predicted_emotion = predict_emotion(sentence)\n",
        "    print(f\"Sentence: '{sentence}'\")\n",
        "    print(f\"Predicted Emotion: {predicted_emotion}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example sentences for prediction\n",
        "sentences = [\n",
        "    \"I am a broken-hearted\",\n",
        "    \"I am emotionaly damaged right now\",\n",
        "    \"Do what makes feel you better\",\n",
        "    \"I feel nervous\",\n",
        "    \"I am a student\",\n",
        "    \"You're stupid and it makes me anger\",\n",
        "    \"Go to hell\",\n",
        "    \"You are the worst,I do not want to see you\",\n",
        "    \"I am angry right now\",\n",
        "    \"You are my sunshine\",\n",
        "    \"Such a wonderful performance\",\n",
        "    \"I am lonely\"\n",
        "]\n",
        "\n",
        "# Perform prediction for each sentence\n",
        "for sentence in sentences:\n",
        "    predicted_emotion = predict_emotion(sentence)\n",
        "    print(f\"Sentence: '{sentence}'\")\n",
        "    print(f\"Predicted Emotion: {predicted_emotion}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NbLBfjVeFtv",
        "outputId": "468e16ee-4df7-402e-c44c-b56f3cd08505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: 'I am a broken-hearted'\n",
            "Predicted Emotion: ([0.22256985306739807, 0.2726081311702728, 0.30142638087272644, 0.20339569449424744], 'angry')\n",
            "\n",
            "Sentence: 'I am emotionaly damaged right now'\n",
            "Predicted Emotion: ([0.22510485351085663, 0.2804677188396454, 0.28153783082962036, 0.2128896266222], 'angry')\n",
            "\n",
            "Sentence: 'Do what makes feel you better'\n",
            "Predicted Emotion: ([0.3086329996585846, 0.20802205801010132, 0.17631801962852478, 0.3070269823074341], 'joy')\n",
            "\n",
            "Sentence: 'I feel nervous'\n",
            "Predicted Emotion: ([0.21537865698337555, 0.3466716706752777, 0.24246057868003845, 0.1954890787601471], 'sad')\n",
            "\n",
            "Sentence: 'I am a student'\n",
            "Predicted Emotion: ([0.29096055030822754, 0.22324411571025848, 0.26276153326034546, 0.2230338305234909], 'joy')\n",
            "\n",
            "Sentence: 'You're stupid and it makes me anger'\n",
            "Predicted Emotion: ([0.21656301617622375, 0.2647278904914856, 0.34241899847984314, 0.17629007995128632], 'angry')\n",
            "\n",
            "Sentence: 'Go to hell'\n",
            "Predicted Emotion: ([0.23550142347812653, 0.2363341897726059, 0.25273290276527405, 0.27543145418167114], 'neutral')\n",
            "\n",
            "Sentence: 'You are the worst,I do not want to see you'\n",
            "Predicted Emotion: ([0.23315386474132538, 0.2811245918273926, 0.26306697726249695, 0.22265461087226868], 'sad')\n",
            "\n",
            "Sentence: 'I am angry right now'\n",
            "Predicted Emotion: ([0.2269899696111679, 0.2489987015724182, 0.33669793605804443, 0.18731342256069183], 'angry')\n",
            "\n",
            "Sentence: 'You are my sunshine'\n",
            "Predicted Emotion: ([0.45811620354652405, 0.198644757270813, 0.15489526093006134, 0.1883438229560852], 'joy')\n",
            "\n",
            "Sentence: 'Such a wonderful performance'\n",
            "Predicted Emotion: ([0.3935435712337494, 0.1811971664428711, 0.1942969560623169, 0.23096232116222382], 'joy')\n",
            "\n",
            "Sentence: 'I am lonely'\n",
            "Predicted Emotion: ([0.26524460315704346, 0.3102840185165405, 0.2299225777387619, 0.19454874098300934], 'sad')\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "\n",
        "# # Load the model from the pickle file\n",
        "# with open(\"test_based_recog_new.pkl\", \"rb\") as f:\n",
        "#     loaded_model2 = pickle.load(f)\n"
      ],
      "metadata": {
        "id": "LQrrsRkXSjKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# max_len =50\n",
        "\n",
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# def get_sequences(tokenizer, tweets):\n",
        "#     sequences = tokenizer.texts_to_sequences(tweets)\n",
        "#     padded = pad_sequences(sequences,truncating= 'post',padding='post', maxlen =max_len)\n",
        "#     return padded"
      ],
      "metadata": {
        "id": "_9K1VNCqXP1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Example usage\n",
        "# def predict2(sentence):\n",
        "#     import numpy as np\n",
        "#     from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "#     from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#     tokenizer  = Tokenizer(num_words = 1000, oov_token = '<UNK>' )\n",
        "#     seq_test = get_sequences(tokenizer, sentence)\n",
        "#     print(seq_text)\n",
        "#     # p = loaded_model2.predict(seq_test)\n",
        "#     # p = np.argmax(p).astype('uint8')\n",
        "#     # print(p)\n",
        "#     # print('Prediction : ',get_emotion_name(p))"
      ],
      "metadata": {
        "id": "DcGFMldhTUfa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}